import ollama
# Query the llama 3 model with a streaming response
